{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import os, fnmatch\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import PolynomialFeatures \n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "# from keras.op\n",
    "from keras import optimizers\n",
    "from keras import regularizers\n",
    "from PIL import Image\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import keras\n",
    "from keras.models import load_model\n",
    "from keras.datasets import cifar10\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, BatchNormalization, Activation\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tiff_files = []\n",
    "listOfFiles = os.listdir('./clean_data/obj_test_res')\n",
    "pattern = \"*.tiff\"\n",
    "for entry in listOfFiles:\n",
    "    if fnmatch.fnmatch(entry, pattern):\n",
    "            all_tiff_files.append('./clean_data/obj_test_res/'+entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42165\n"
     ]
    }
   ],
   "source": [
    "print(len(all_tiff_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_list = []\n",
    "half_size = int(len(all_tiff_files) / 2)\n",
    "max_size = 0\n",
    "max_width = 0\n",
    "max_height = 0\n",
    "ind = 0\n",
    "for i in range(half_size):\n",
    "#    if(i == 25232):\n",
    "#        print(all_tiff_files[i])\n",
    "    im = Image.open(all_tiff_files[i])\n",
    "    arr = np.array(im)#.flatten()\n",
    "    #arr = np.expand_dims(arr, axis=1)\n",
    "    s = arr.shape\n",
    "    if s[0] > max_height:\n",
    "        max_height = s[0]\n",
    "    if s[1] > max_width:\n",
    "        max_width = s[1]\n",
    "        ind = i\n",
    "    images_list.append(arr)\n",
    "\n",
    "for i in range(half_size, len(all_tiff_files)):\n",
    "#    if(i == 25232):\n",
    "#        print(all_tiff_files[i])\n",
    "    im = Image.open(all_tiff_files[i])\n",
    "    arr = np.array(im)#.flatten()\n",
    "    #arr = np.expand_dims(arr, axis=1)\n",
    "    s = arr.shape\n",
    "    if s[0] > max_height:\n",
    "        max_height = s[0]\n",
    "    if s[1] > max_width:\n",
    "        max_width = s[1]\n",
    "        ind = i\n",
    "    images_list.append(arr)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27 140 7748\n",
      "[[ 1560   260     0   624   164     0    64  1944   660     0]\n",
      " [ 1120     0     0    32     0     0     0  1666  1424   196]\n",
      " [   48     0     0     0     0     0     0   814  1606  1360]\n",
      " [    0     0     0   804   672   142     0     0     0     0]\n",
      " [    0     0   674  1390   944   836   636     0     0     0]\n",
      " [    0     0   730   748     0     0     0     0     0     0]\n",
      " [  960   798   152     0     0     0     0     0     0     0]\n",
      " [ 1900   884     0     0     0     0   198     0     0     0]\n",
      " [ 1112     0     0     0     0  1616  1502     0     0     0]\n",
      " [  304     0     0     0   306  3456  3062     0     0     0]\n",
      " [    0     0     0     0  1726  6322  5726  1588     0     0]\n",
      " [    0     0     0     0  3408  9158  7870  2618     0     0]\n",
      " [    0     0     0     0  3538 10188  8222  1618     0     0]\n",
      " [    0     0     0     0  2872 10400  8268   410     0     0]\n",
      " [    0     0     0     0  3316 10988  8758   298     0     0]\n",
      " [  356     0     0     0  3764 10520  8044     0     0     0]\n",
      " [  636     0     0     0  3364  9272  6596     0     0     0]\n",
      " [  688     0     0     0  3190  9010  6348     0     0     0]\n",
      " [  664     0     0     0  2586  8588  6166     0     0     0]\n",
      " [  260     0     0     0   920  7056  5148     0     0     0]\n",
      " [    0     0     0     0    24  6134  4940     0     0     0]\n",
      " [    0     0     0     0  1134  6570  5550   298     0     0]\n",
      " [    0     0     0     0  2558  6778  5370   844     0     0]\n",
      " [    0     0     0     0  1996  5602  4394  1004     0     0]\n",
      " [    0     0     0     0   370  4168  3794  1036     0     0]\n",
      " [    0     0     0     0   640  4490  4448   848     0     0]\n",
      " [    0     0     0     0  1606  5582  5500   684     0     0]\n",
      " [    0     0     0     0   498  5010  5270    66     0     0]\n",
      " [    0     0     0     0     0  4078  4524     0     0     0]\n",
      " [  264    74     0     0   732  4282  4078     0     0     0]\n",
      " [    0     0     0     0  1268  3968  2944     0     0     0]\n",
      " [    0     0     0     0   808  3146  1834     0     0     0]\n",
      " [    0     0     0     0  1754  3754  2322     0     0     0]\n",
      " [    0     0     0   666  2984  4772  3278     0     0     0]\n",
      " [    0     0     0     0  2304  4380  3202   232     0     0]\n",
      " [    0     0     0     0  1434  3878  2868   288     0     0]\n",
      " [    0     0     0     0  1712  4530  3196     0     0     0]\n",
      " [    0     0     0     0  1558  5064  3692     0     0     0]\n",
      " [    0     0     0     0   496  4542  3838     0     0     0]\n",
      " [    0     0     0     0     2  4136  4036   620     0     0]\n",
      " [    0     0     0     0   844  4754  4484  1158     0     0]\n",
      " [  168     0     0     0  1582  5386  4632   728     0     0]\n",
      " [  920     0     0     0  1036  5342  4590   240     0     0]\n",
      " [ 1104     0     0     0   648  5234  4690   266     0     0]\n",
      " [  200     0     0     0  1940  5740  4788   522     0     0]\n",
      " [    0     0     0     0  3660  6746  4924   484     0     0]\n",
      " [    0     0     0     0  3346  7066  4990   194     0     0]\n",
      " [    0     0     0     0  1586  6264  4732   136     0     0]\n",
      " [  312     0     0     0  1086  5830  4420    34     0     0]\n",
      " [   44     0     0     0  2046  6544  4214     0     0     0]\n",
      " [    0     0     0     0  2882  7288  3916     0     0     0]\n",
      " [    0     0     0     0  2678  6890  3326     0     0     0]\n",
      " [    0     0     0     0  1954  6106  3264     0     0     0]\n",
      " [   48     0     0     0  1734  6130  4216     0     0     0]\n",
      " [    0     0     0     0  2382  6394  4420     0     0     0]\n",
      " [    0     0     0     0  3612  6304  3358     0     0     0]\n",
      " [    0     0     0   190  4024  5842  2728     0     0     0]\n",
      " [    0     0     0     0  3408  5190  2936   250     0     0]\n",
      " [    0     0     0     0  2912  5068  3194     0     0     0]\n",
      " [    0     0     0     0  2452  5656  3584     0     0     0]\n",
      " [    0     0     0     0  1940  6310  4166     0     0     0]\n",
      " [    0     0     0     0  1902  6704  4274     0     0     0]\n",
      " [    0     0     0     0  2018  6600  3524     0     0     0]\n",
      " [    0     0     0     0  1568  5552  2070     0     0     0]\n",
      " [    0     0     0     0  1316  4912  1524     0     0     0]\n",
      " [    0     0     0     0  2580  6008  2610     0     0     0]\n",
      " [    0     0     0     0  4002  7028  3306     0     0     0]\n",
      " [    0   348     0     0  4126  6682  2694     0     0     0]\n",
      " [    0     0     0     0  3376  5776  1986     0     0     0]\n",
      " [    0     0     0     0  1968  4556  1852     0     0     0]\n",
      " [    0     0     0     0   892  3490  2122     0     0     0]\n",
      " [    0     0     0     0  1186  3114  2102     0     0     0]\n",
      " [    0     0     0     0  1764  2800   846     0     0     0]\n",
      " [    0     0     0     0  2012  2386     0     0     0     0]\n",
      " [    0     0   282   356  2216  2346     0     0     0     0]\n",
      " [    0     0     0   314  2280  2920   734     0     0     0]\n",
      " [  412     0     0     0  2172  3360  1688     0     0     0]\n",
      " [ 1324     0     0     0  1684  2626   750     0     0     0]\n",
      " [ 1212    96     0     0   976  1664     0     0     0     0]\n",
      " [    0     0     0     0  1022  1872     0     0     0     0]\n",
      " [    0     0     0     0  1480  2204   582     0     0     0]\n",
      " [    0     0     0     0  1524  1596   698   730     0     0]\n",
      " [  704   976   736   620  1460  1100   592  1060     0     0]]\n"
     ]
    }
   ],
   "source": [
    "print(max_width, max_height, ind)\n",
    "print(images_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(images_list)):\n",
    "    s = images_list[i].shape\n",
    "    d_width = (max_width - s[1])\n",
    "    d_height = (max_height - s[0])\n",
    "    \n",
    "    d_top = int(d_height / 2)\n",
    "    d_bottom = int(d_height - d_top)\n",
    "    \n",
    "    d_left = int(d_width / 2)\n",
    "    d_right = int(d_width - d_left)\n",
    "    #print(d_top, d_bottom, d_left, d_right)\n",
    "    \n",
    "    arr = images_list[i]\n",
    "    for l in range(d_left):\n",
    "        arr = np.insert(arr, 0, 0, axis = 1)\n",
    "    \n",
    "    for r in range(d_right):\n",
    "        b = np.zeros((s[0],1))\n",
    "        arr = np.append(arr, b, axis = 1)\n",
    "    \n",
    "    for t in range(d_top):\n",
    "        arr = np.insert(arr, 0, 0, axis = 0)\n",
    "    \n",
    "    for b in range(d_bottom):\n",
    "        b = np.zeros((1, arr.shape[1],))\n",
    "        arr = np.append(arr, b, axis = 0)\n",
    "    \n",
    "    images_list[i] = arr\n",
    "    \n",
    "    #if i == 1024:\n",
    "    #    plt.imshow(arr)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27 140\n"
     ]
    }
   ],
   "source": [
    "width = max_width\n",
    "height = max_height\n",
    "print(width, height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(images_list[74])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#min_max_scaler = preprocessing.MinMaxScaler()\n",
    "images_np = np.array(images_list)\n",
    "images_np /= 0xffff\n",
    "#X_train_minmax = min_max_scaler.fit_transform(images_np)\n",
    "X_train, X_test = train_test_split(images_np, test_size=0.33, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (28250, 140, 27)\n",
      "28250 train samples\n",
      "13915 test samples\n"
     ]
    }
   ],
   "source": [
    "print('x_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(28250, 140, 27, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.reshape(13915, 140, 27, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 14517204692061540317\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 1441641267\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 13310348708585866977\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 750 Ti, pci bus id: 0000:01:00.0, compute capability: 5.0\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "config = tf.ConfigProto( device_count = {'GPU': 1 , 'CPU': 8} ) \n",
    "sess = tf.Session(config=config) \n",
    "keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = Input(shape=(height, width, 1))\n",
    "x = Conv2D(64, (2, 2), padding='same')(input_img)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D((2, 1))(x)\n",
    "x = Conv2D(32, (2, 2), padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D((2, 1))(x)\n",
    "x = Conv2D(16, (2, 2), padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "encoded = MaxPooling2D((5, 1))(x)\n",
    "\n",
    "x = Conv2D(16, (2, 2), padding='same')(encoded)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = UpSampling2D((5, 1))(x)\n",
    "x = Conv2D(32, (2, 2), padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = UpSampling2D((2, 1))(x)\n",
    "x = Conv2D(64, (2, 2), padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = UpSampling2D((2, 1))(x)\n",
    "x = Conv2D(1, (2, 2), padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "decoded = Activation('relu')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 140, 27, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 140, 27, 64)       320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 140, 27, 64)       256       \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 140, 27, 64)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 70, 27, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 70, 27, 32)        8224      \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 70, 27, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 70, 27, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 35, 27, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 35, 27, 16)        2064      \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 35, 27, 16)        64        \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 35, 27, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 7, 27, 16)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 7, 27, 16)         1040      \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 7, 27, 16)         64        \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 7, 27, 16)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_10 (UpSampling (None, 35, 27, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 35, 27, 32)        2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 35, 27, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 35, 27, 32)        0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_11 (UpSampling (None, 70, 27, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 70, 27, 64)        8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 70, 27, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 70, 27, 64)        0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_12 (UpSampling (None, 140, 27, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 140, 27, 1)        257       \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 140, 27, 1)        4         \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 140, 27, 1)        0         \n",
      "=================================================================\n",
      "Total params: 23,141\n",
      "Trainable params: 22,691\n",
      "Non-trainable params: 450\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(input_img, decoded)\n",
    "model.compile(optimizer='adam', loss='MSE')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 500 samples, validate on 100 samples\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "2 root error(s) found.\n  (0) Resource exhausted: OOM when allocating tensor with shape[500,64,140,27] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node training_5/Adam/gradients/zeros_25}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[loss_5/mul/_1585]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n  (1) Resource exhausted: OOM when allocating tensor with shape[500,64,140,27] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node training_5/Adam/gradients/zeros_25}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n0 successful operations.\n0 derived errors ignored.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-64-d7b0959125e5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m                     shuffle=True)\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1472\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1473\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: 2 root error(s) found.\n  (0) Resource exhausted: OOM when allocating tensor with shape[500,64,140,27] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node training_5/Adam/gradients/zeros_25}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[loss_5/mul/_1585]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n  (1) Resource exhausted: OOM when allocating tensor with shape[500,64,140,27] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node training_5/Adam/gradients/zeros_25}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n0 successful operations.\n0 derived errors ignored."
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train[:500], X_train[:500],\n",
    "                    batch_size=1024,\n",
    "                    epochs=1000,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_test[:100], X_test[:100]),\n",
    "                    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = X_test[1].reshape(140, 27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x287b8e165c8>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFYAAAD8CAYAAADt0VN/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAATsklEQVR4nO2dXYwkV3XHf6eq+mN6vmd2d3a9u9hr7EAMAUwsDEGJopAohiBIpCCBIoISJCcSJJBvTB7gkSgJ+XgIkhMciGRBiCGKHxwIEFCUBxwbx8E2i83iBe+sx7uzuzOzs9PT3VNVJw/3dk/PTHXPeLpv99T6/qTSdlffrrrz39On7se554qq4uk/wbArcL3ihXWEF9YRXlhHeGEd4YV1hDNhReQuEXlaRM6IyEdc3eegIi7asSISAs8AvwDMA48A71HV7/b9ZgcUVxb7BuCMqj6rqg3g88A7Hd3rQBI5uu5x4Fzb+3ngzk6Fi1LSMqOOqtI/Vlm6pKqH91LWlbCScW6LzxGRu4G7AcpUuFPe4qgq/eNr+sCP9lrWlSuYB062vT8BPN9eQFXvVdU7VPWOAiVH1RgeroR9BLhVRE6JSBF4N/Cgo3sdSJy4AlWNReSDwFeAELhPVZ9yca+Diisfi6o+BDzk6voHHd/zcoQX1hFeWEd4YR3hhXWEF9YRXlhHeGEd4YV1hBfWEV5YR3hhHeGFdYQX1hFeWEd4YR3hhXWEF9YRXlhHeGEd4YV1hBfWEfsWVkROisg3ROS0iDwlIh+y52dE5Ksi8n3773T/qpsferHYGPgDVf1x4I3AB0TkNuAjwNdV9Vbg6/b9S459C6uqC6r6mH29CpzGRBm+E/isLfZZ4Jd7rWQe6UskjIjcBNwOPAzMqeoCGPFF5Eg/7rEbQaViXoQh6epqs2KbBQa8ULDnh5eIjAFfBD6sqldfxPfuFpFHReTRDeq9VuPA0ZOwIlLAiHq/qn7Jnr4gIsfs58eAi1nf7XcYZ1qtklarkCRtFQw2jwGzb1cgIgJ8Gjitqp9s++hB4H3AJ+y//9ZTDbff9/ZXEV4xP4z4R+d2fl4sEITjrdctkoRkeWVr2UIR3Wj0s3otevGxbwbeCzwhIo/bcx/FCPoFEXk/8Bzwrt6qmE/2Layq/jfZIfEAzuLer75inMoF4zoKFxYBSGs1opteZupVLBBsxK3XUjcWqSurO64Vzk4Tv3DBST2dxcc6QyFopIARtHX6yjIAMj4GBfNnSb1B/Nx5UyBN2I4mqbNq+i6tI3JnsVOPX4IF09Bot8Hkqm3pXb2KFIoASLmUaamt7ywuuqpm/oRNnj6za5nmkz6YHIedrnUgeFfgiNxZbDg1iTY2zBvbZU3Xa9k/+TBEIvMnahy3XISrtms73mIdkTuLlXIZwtC8mZ405yYrBN83vbDWQwxIFi8TlE2bV+N4IJbaJHfCJkvLaN0O2ly+AkB4aJZkNasDMIMemzVvvvO9QVUR8K7AGbmz2PD4MeJnf7jlXHLpcmbZy3fdwuqN5gH3stJPoI884bp6LXIn7PrNs5SefwHY2qVtJzxkfv4Xfzrmzlf9AIDT117J0UcGU0fwrsAZubNYABmz2Tg6WKzaEa25E0v80Q1fBuBdt9zK0YHUzpA7YaP1xIxgAXTwrc05r5HCDD9ZMp2CaLbWchGdfHI/8a7AEbmz2KC2QTo+ArCrBZ6/PMlCfA2AjWphIJbaJHfChhdXILQ/tJGRrmWThQoPrd0CQGm+6LpqW/CuwBG5s9j43PzmmyDsWjYtpSxsTAFQWHNZq514i3VE7ix2Cx2mXYJxE1dQmKlRS01sQXRtYLUy9+v1AjZB5KPAeVV9u4icwuQynAEeA95r8xsODG2Y28X1iCdXbgBg+pnBhjH1wxV8CBNp2OTPgL+yYZxLwPv7cI/c0Wvs1gngl4B/sO8F+DngAVuk72Gc0akbCaenCac7xzNrvW6O9YgrtQpXahXK51Y6lndBr67gr4E/Bsbt+1lgWVVj+34eEzPbNzaOTRGVbZt0aalr2WiiwUy5CkBtfE9JNPtGL6Hybwcuquq3209nFM0MTL3ewzh7DYp7h4i8DSgDExgLnhKRyFrtjiycTVT1XuBegAmZ2XNUcLAeI/WNrmWi4+aBVanUCcSGI5WijoFmLuglVP4eVT2hqjdhsm3+p6r+GvAN4Fdtsb6HcQZn50nOPU9yLvP/C4B0dsIcKpxdmuXs0iyFheV+VmNXXHQQ/gT4fRE5g/G5n3ZwjwNPXzoIqvpN4Jv29bOYHN1O2B48nEU8aQZnkmSD9aqd/l7JDCx3hu/SOuK6FDaoxwT1mEa9gKagKXBkdqB1yN1YQXTyBFozzTNdM0NWabW6tczzJpAjvXyCYMO0BaR6aYC1vE4t9iCQO4slChE7g5AmHYKKIzNOG2wIE2eMxWatsHFJ7oRNzp1H47hrmfqpQwDoXJ3gdLlzQRFnKxa9K3BE7ix2N2sFSIrGXkrlGo3JLhOODtfX5k7YoD0+1vrY7TFcUdWcX79aZmL3/wcneFfgiPxZ7A1HSSfMEnpZtzM+21bSbIzZP2sDgu4DYc7InbAabU55Sy17HFfD5gChknRpFLjEuwJH5M5ieWERsWtl46Xska7mw0s2ImRIO3B7i3VE7iy2fblRJ8S2T2VDiNaGY7K5E3YvaGAeXsWVgMpi50XKLvGuwBG5s9hwYmKz56VmBnZHrpfU/PxHLijjz5hJxEHbbe6EldEKmtrMGOvZizuaROsgVwYbAdPEuwJH5M5i02trm5ngOlCfNqGbjQkhnTWBxyy8sKNcdHTOWbKdXoPipkTkARH5ns3K+SbX2Til0n3dQTg9zeqJkNUTIWvHlepNE1Rvmsgs60pU6N0V/A3wZVV9JfBaTDinz8ZJb0FxE8DPYCNdVLWhqsu4zsY5M9n1Y41jNAQNIRlNScpCUh5k1JahFx97M7AI/KOIvBb4NiYI2W02zkvdY7DS1VWKy6a5VVgJGLnQveXgil5cQQS8HviUqt4OrPEifvbXexhnL8LOA/Oq+rB9/wBGaKfZONM9xG6lBXOE60LxuUsUn8sO1gjK7gZrewnjfAE4JyKvsKfeAnyXzWyc4CCMMy/02o79HeB+uyP9s8BvYP6znGXjDKYmwSbNyYo8DMpl1uds2qiCkpxf2HmRZlqpujsX1JOwqvo4cEfGR86ycVKvdx06lJER6rOmyxuuS/Z0+QDSSvsurSPy16XdZeBFSkXSihnLCmvD+/NyJ2x45BDY0a04o/+v9UZrnU5Qz+4YNJeE7jbm0AveFTgidxYLoOvrHT+TsVGkbF1BvZBZJl0zgcpSKm1mneszuRM2vbra9SecHJ1matpEel8b79DxsKvGte5uXsG7AkfkTthgapfRLQERRUSJx9wlN9+N3LkCHa8QjJqEZunaznwkGgWs122O7njww4VNcmexeSF3Fitr6yQZltqkekOZkZJZbh93aMcOAm+xjsidxWq1e5e2NhkQBqbrVVzeZrHNdFJd9kboF/kTtkMGziaFdeXSinm4TSxtG8UagKBNvCtwRO6EbXZHOxFsbFppGg3v4ZU7V9AMhOtEYyxgetK0GtbsIpBhkDuLzQu5E7a1m2cHwoaiKqjK0NYfQB6FnRg3zaYOmTjLywlLVyssXa1QXuygrP1+dKKvKcG23sLZlV/i5O/hFQSIXWOQ9Ry7djRCMMsRyyvZD7pgxARq6Li7h1uvYZy/ZzdUf1JEPiciZRE5JSIP2zDOf7YxB31Dq+sm8G3btHY4NUk4NcmV1ygT41UmxqsEcbYrSNfWSNfWkNXuTbde6CXa8Djwu8AdqvpqIMQkNvPZOOndx0bAiIhEQAVYwHE2zo75Co4cgiOH0NGY5eVRlpdHGXm+89wYdJ8765VeYrfOA3+BCSNaAFYwoZxOs3HmhV62qJ7GBBmfApaBfwHemlG0YzZO4G6AMi/iIdIhwU7yjNmsp3DxTYTNGYT/fTTz5s24AjbcZYnoxRX8PHBWVRdVdQP4EvBT2GyctkzXbJz7CeMMZme6fl5YFcIahLWdeyNKoYgUigRjowRjo2inLEh9oBdhnwPeKCIVm+m4GcbpNBtnXujFxz6MeUg9Bjxhr3UvjrNxJkcmCcrljkHDSRkaU0pjSgm3WbduNNCNholNuLq6p8Q9+6XXMM6PAR/bdtppNk5SkKJtGrcNejeT8TZmEnTEJuG5+XhrX8Utl7CBdeHMFImjSBjfpXVE7rq0kiRQ2vmw0zHbshiPKZTMTzyNgsz00aHddjW+9QTiaMek3AlLCgQZcl02U95am2EjNZ8XFi7SzYsmlciZAN4VOCJ3FitpilZ3dkWbm6AVF3+slUIq/uFzmddI7AOt9GTkLI9B7oTVQtjaSyaLqCqEe9zZJrngLm+3dwWOyJ3Fylqt6/osUZAOT6zmfFlrab4EJIuL/a6iuZeTq3ryZ7HJmbO7lkk7jOkEMyYnhdpNgLRcAkcWmzthOyEFI1ZS6uwKkgtGxOao125T6b3gXYEjrhuLDU+aQZi0oBTXs2O2to/Pbt8/oZ/kT9ggzAzH1JJZ0xXWheLKEENgLN4VOCJ/wu4SPBzWIGiYQ6Lh/SDzJ2yHmC0thGghJKqCpOYIT2ZPEAeVCkGlsmOGoa/VdHbllzj5e3hluIJwYoJ41PQKRi6nlJbtWtlrW5/64ZzNVGVnZ7NGyfpF/oTNQCYnCBqmVzD+7BrhWZPHYMc4gBW0OWzoMoWJdwWOuC4sNj43T2jjsGRkhLhT/79poT7ZTn7ZVVgRuU9ELorIk23nMlOZiuFvReSMiHxHRF7vsvLtaL1hjonRzqH0M1MwM9U14KNf7MViPwPcte1cp1SmbwVutcfdwKf6U81NwlfcsmNTdSkU4eYTcPMJqjdOEB2bIzo2t+O7srqGrK4RTE8RTE+1RsRcsKuwqvpfwPZwkk6pTN8J/JMavoUJkDvWr8rmif0+vDqlMj0OtG9O2IyP3ZEHb99hnKrIlMlgHLVlP06KdpuUkYD0kM3CcX5roGMrw7FNwdcKVXJAv1sFe96tfr+bqjfjYHfc+KLJuDkavhKpmcUdUigSTNpY2DjezIVoWwWuMhjB/lsFnVKZzgMn28p1jI+93tmvsJ1SmT4I/LptHbwRWGm6DNc0QzTDp8+RPH2G5OkzZmD78Iw55g4jUbTlCCeyk6L3g11dgYh8DvhZ4JCIzGPCNj9BdirTh4C3AWeAKibt6UDZ8fNeMD8mrdV3xMO6jOjeVVhVfU+Hj3akMlVVBT7Qa6WuB3LZpW3OrgbTZvOI5OIlwuNHzYcipGd/1Cqblby3SVZ6qX6RS2FbP2G7E104d5jksGliSSNuzRy4DIXfDT9W4IhcWmyzYa/WYmUjJqhuTm0Hh83e3/GFxYEm2GnHW6wj8mmxtisr66ZpFZ9/HrlorDiYmoSSeR3NHUZju+NnsdBqiiWO1h20kz9hRUjt1Er7w6kZ5ZIurxCM2aSSq5truYJKZfM/ZAAPN+8KHJE7iw3GxrpmPG7PL9tukWm1SmgttblIWdfXd+x03y9yJ6yUy4id39ryU27OGByeRtZ2yVNgv+dKVPCuwBm5s1hgc/vUNouNjpi2a1qMkGp2GOdedmHuF7kTVkpFNCOBQ3rEzIHF4yUK1+xUeBQNrVvrXYEjcmexurGR2U1tHDJt18ZURLRk4rgkijYHbFQHOjjjLdYRubPYTss0i5dNZGFSGkOsD1YgsEvw01qt9dBrPtoObIaNodBhDUL6xDMAjF6aa3V5t7dTm2MFrSgYCXYs+OhbNZ1c1ZM/iw1ffiNiM8u3Jg7jGK2Z1+nlK7v2qNTGFQST485GunInLEsrJKvXzOvUCjSzGYeltRpB05cWosw5r2Y7eC9bse4X7wocsd8wzj+3O9R/R0T+VUSm2j67x4ZxPi0iv9jvCieXLqP1ujlskEZy4SLp1avmaMs6L+PjREfniI7ayMNt4Z3DHo/9DDvDOL8KvFpVXwM8A9wDICK3YVKdvsp+5+9EJHv9UJ9pik2atPLDxufmiV+4sBkMlyZbD4fsK4xTVf+jLePmtzAxWmDCOD+vqnVVPYuJiHGX3OwA0w8f+5vAv9vXncI4X3L01CoQkT8FYuD+5qmMYv1Nc5oTeskf+z7g7cBbVFvLUPYcxrnf+Ni8sC9XICJ3YbJuvkNV25f/PQi8W0RKInIKsxbhf3qvZv7YbxjnPUAJ+KpJHcu3VPW3VfUpEfkCJo9sDHxAVYcTijJkRAewmGw3JmRG7xR3G9z3i6/pA99W1Tv2Utb3vBzhhXWEF9YRXlhHeGEd4YV1hBfWEV5YR3hhHeGFdYQX1hFeWEd4YR3hhXWEF9YRXlhHeGEd4YV1hBfWEV5YR3hhHeGFdYQX1hFeWEd4YR1xICJhRGQRWAMuDbsuHTiEqduNqnp4L184EMICiMijew3fGTT7qZt3BY7wwjriIAl777Ar0IUXXbcD42OvNw6SxV5XDF1YEbnLLrY7IyIf2f0bTutyUkS+ISKnReQpEfmQPf9xETkvIo/b4227XkxVh3YAIfAD4GagCPwfcNsQ63MMeL19PY5ZHHgb8HHgD1/MtYZtsW8Azqjqs6raAD6PWYQ3FFR1QVUfs69XgdPsc53asIU9sAvuROQm4HbgYXvqg3bt8H3NLWC6MWxh97zgbpCIyBjwReDDqnoVs7XLy4HXYTbL+MvdrjFsYQ/cvgkiUsCIer+qfglAVS+oaqKqKfD37GF98LCFfQS4VUROiUgRs3L8wWFVRsyitU8Dp1X1k23n2/fL+RXgye3f3c5QM2yoaiwiHwS+gmkh3KeqTw2xSm8G3gs8ISKP23MfBd4jIq/DuKkfAr+124V8z8sRw3YF1y1eWEd4YR3hhXWEF9YRXlhHeGEd4YV1xP8DRrgDxmDCSrkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_img = model.predict(X_test[1].reshape(1, 140, 27, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x287b8e6f148>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(result_img.reshape(140, 27))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
